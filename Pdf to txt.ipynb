{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5716fc",
   "metadata": {},
   "source": [
    "## Amanda Cesario's notebook for DS Final Project\n",
    "### Question 5: How does IonQ's risk factors change over time?\n",
    "### Group 3 members: Cole Barrett, Caterina Grossi, Connor Steward\n",
    "This notebook is my process for converting a pdf to a txt file, cleaning the text file, then extracting the Item 1A Risk Factors to begin my analysis using OpenAI API (in the notebook \"OpenAI - Final Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c359666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2a7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f19abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted IONQ 2024 10K.pdf to IONQ 2024 10K.txt\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def pdf_to_txt(pdf_path, txt_path):\n",
    "    # Extract text from the PDF file\n",
    "    text = extract_text(pdf_path)\n",
    "    # Write the extracted text to a TXT file\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"IONQ 2024 10K.pdf\"\n",
    "    txt_file = \"IONQ 2024 10K.txt\"\n",
    "    pdf_to_txt(pdf_file, txt_file)\n",
    "    print(f\"Converted {pdf_file} to {txt_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c16fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text saved to IONQ 2024 10K_clean.txt\n"
     ]
    }
   ],
   "source": [
    "def clean_text_file(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "        raw_text = infile.read()\n",
    "    \n",
    "    cleaned_text = clean_text(raw_text)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(cleaned_text)\n",
    "    print(f\"Cleaned text saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_txt = \"IONQ 2024 10K.txt\"  # the original converted text file\n",
    "    output_txt = \"IONQ 2024 10K_clean.txt\"  # the cleaned text file\n",
    "    clean_text_file(input_txt, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97299b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted section saved to IONQ 2024 10K_Item1A.txt\n"
     ]
    }
   ],
   "source": [
    "def extract_item_1A_section(text):\n",
    "    \"\"\"\n",
    "    Extracts the text starting from \"Item 1A\" up to (but not including) \"Item 2\".\n",
    "    The search is case-insensitive and spans multiple lines.\n",
    "    \"\"\"\n",
    "    # Define start and end patterns\n",
    "    start_pattern = r'Item\\s*1A\\s*[:.-]?.*Risk\\s*Factors'\n",
    "    end_pattern = r'Item\\s*2'\n",
    "    \n",
    "    # Use re.DOTALL so '.' matches newlines; re.IGNORECASE for case insensitivity.\n",
    "    pattern = re.compile(f'({start_pattern}.*?){end_pattern}', re.DOTALL | re.IGNORECASE)\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        # Return the matched group (the section content)\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to open the file, run the Item 1A extraction func, then saves it once the file is done\n",
    "def extract_and_save_section(input_path, output_path):\n",
    "    # Read the entire text file\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "        full_text = infile.read()\n",
    "    \n",
    "    # Extract the \"Item 1A: Risk Factors\" section\n",
    "    section = extract_item_1A_section(full_text)\n",
    "    \n",
    "    if section:\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(section)\n",
    "        print(f\"Extracted section saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"The section 'Item 1A: Risk Factors' could not be found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_txt = \"IONQ 2024 10K_clean.txt\"      # Cleaned text file from earlier\n",
    "    output_txt = \"IONQ 2024 10K_Item1A.txt\"      # File to save the extracted section\n",
    "    extract_and_save_section(input_txt, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ae12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted section saved to IONQ 2023 10K_Item1A.txt\n"
     ]
    }
   ],
   "source": [
    "# Rinse and repeat with however many years of 10-K's you have, changing the input and output file path names each time\n",
    "if __name__ == \"__main__\":\n",
    "    input_txt = \"IONQ_2023_Cleaned.txt\"      \n",
    "    output_txt = \"IONQ 2023 10K_Item1A.txt\"      \n",
    "    extract_and_save_section(input_txt, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d26794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted section saved to IONQ 2022 10K_Item1A.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_txt = \"IONQ_2022_Cleaned.txt\"      \n",
    "    output_txt = \"IONQ 2022 10K_Item1A.txt\"      \n",
    "    extract_and_save_section(input_txt, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a45654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted section saved to IONQ 2021 10K_Item1A.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_txt = \"IONQ_2021_Cleaned.txt\"      \n",
    "    output_txt = \"IONQ 2021 10K_Item1A.txt\"     \n",
    "    extract_and_save_section(input_txt, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155e684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
